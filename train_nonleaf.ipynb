{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "dataset_dir = 'Classification'  # Change this to your dataset path\n",
    "leaf_dir = os.path.join(dataset_dir, 'leaf')\n",
    "leaves_dir = os.path.join(dataset_dir, 'leaves')\n",
    "processed_dir = os.path.join(dataset_dir, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs(os.path.join(processed_dir, 'train', 'leaf'), exist_ok=True)\n",
    "os.makedirs(os.path.join(processed_dir, 'train', 'leaves'), exist_ok=True)\n",
    "os.makedirs(os.path.join(processed_dir, 'val', 'leaf'), exist_ok=True)\n",
    "os.makedirs(os.path.join(processed_dir, 'val', 'leaves'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing leaf: 3595 training images, 899 validation images\n",
      "Processing leaves: 911 training images, 228 validation images\n",
      "Found 4506 images belonging to 2 classes.\n",
      "Found 1127 images belonging to 2 classes.\n",
      "Data preprocessing complete!\n",
      "Training samples: 4506\n",
      "Validation samples: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image preprocessing parameters\n",
    "img_size = (800, 800)  # Updated size for resizing images\n",
    "batch_size = 32\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(img_path, target_size=img_size):\n",
    "    # Read image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Error reading image: {img_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize image\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Apply additional preprocessing as needed\n",
    "    # Example: Contrast enhancement\n",
    "    # img = cv2.convertScaleAbs(img, alpha=1.2, beta=10)\n",
    "    \n",
    "    # Normalize pixel values to [0,1]\n",
    "    img = img / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Function to split dataset into train and validation sets\n",
    "def split_and_preprocess_dataset(class_dir, class_name, train_ratio=0.8):\n",
    "    image_paths = [os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Split into train and validation\n",
    "    train_paths, val_paths = train_test_split(image_paths, train_size=train_ratio, random_state=42)\n",
    "    \n",
    "    print(f\"Processing {class_name}: {len(train_paths)} training images, {len(val_paths)} validation images\")\n",
    "    \n",
    "    # Process and save training images\n",
    "    for i, img_path in enumerate(train_paths):\n",
    "        img = preprocess_image(img_path)\n",
    "        if img is not None:\n",
    "            output_path = os.path.join(processed_dir, 'train', class_name, f\"{i}.jpg\")\n",
    "            plt.imsave(output_path, img)\n",
    "    \n",
    "    # Process and save validation images\n",
    "    for i, img_path in enumerate(val_paths):\n",
    "        img = preprocess_image(img_path)\n",
    "        if img is not None:\n",
    "            output_path = os.path.join(processed_dir, 'val', class_name, f\"{i}.jpg\")\n",
    "            plt.imsave(output_path, img)\n",
    "\n",
    "# Process both classes\n",
    "split_and_preprocess_dataset(leaf_dir, 'leaf')\n",
    "split_and_preprocess_dataset(leaves_dir, 'leaves')\n",
    "\n",
    "# Create data generators for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data generator (no augmentation)\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(processed_dir, 'train'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # binary classification: leaf vs leaves\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(processed_dir, 'val'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Data preprocessing complete!\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "\n",
    "# Visualize some processed images\n",
    "def show_processed_samples(generator, title, num_samples=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    images, labels = next(generator)\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"{'Leaf' if labels[i] < 0.5 else 'Leaves'}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample processed images\n",
    "show_processed_samples(train_generator, \"Sample Processed Training Images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "img_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to classify single leaf vs bunch of leaves\n",
    "def train_leaf_classifier(train_dir, val_dir):\n",
    "    # Data generators\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        classes=['leaf', 'leaves']  # Single leaf vs bunch of leaves\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        classes=['leaf', 'leaves']\n",
    "    )\n",
    "    \n",
    "    # Build model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binary: single leaf (0) vs bunch of leaves (1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=15,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save('leaf_classifier_model.h5')\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training leaf classifier model...\n",
      "Found 4506 images belonging to 2 classes.\n",
      "Found 1127 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "141/141 [==============================] - 17s 116ms/step - loss: 0.1287 - accuracy: 0.9507 - val_loss: 0.0239 - val_accuracy: 0.9911\n",
      "Epoch 2/15\n",
      "141/141 [==============================] - 14s 101ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.0124 - val_accuracy: 0.9982\n",
      "Epoch 3/15\n",
      "141/141 [==============================] - 14s 98ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.0306 - val_accuracy: 0.9902\n",
      "Epoch 4/15\n",
      "141/141 [==============================] - 14s 101ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.0060 - val_accuracy: 0.9991\n",
      "Epoch 5/15\n",
      "141/141 [==============================] - 14s 99ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 6/15\n",
      "141/141 [==============================] - 14s 102ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
      "Epoch 7/15\n",
      "141/141 [==============================] - 14s 102ms/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 0.0021 - val_accuracy: 0.9991\n",
      "Epoch 8/15\n",
      "141/141 [==============================] - 14s 102ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0024 - val_accuracy: 0.9982\n",
      "Epoch 9/15\n",
      "141/141 [==============================] - 15s 103ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "141/141 [==============================] - 14s 101ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 7.4218e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "141/141 [==============================] - 14s 99ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0018 - val_accuracy: 0.9991\n",
      "Epoch 12/15\n",
      "141/141 [==============================] - 14s 101ms/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 0.0023 - val_accuracy: 0.9991\n",
      "Epoch 13/15\n",
      "141/141 [==============================] - 14s 101ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 6.8213e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "141/141 [==============================] - 14s 100ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 15/15\n",
      "141/141 [==============================] - 14s 100ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.0053 - val_accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Train model\n",
    "    print(\"Training leaf classifier model...\")\n",
    "    train_leaf_classifier('Classification/train', 'Classification/val')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to crop individual leaves from bunch images\n",
    "def crop_individual_leaves(image_path, output_dir, base_filename):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return []\n",
    "    \n",
    "    # Create grayscale for processing without modifying original image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply threshold to create binary image\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours by area to remove noise\n",
    "    min_contour_area = 1000  # Adjust based on your images\n",
    "    valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
    "    \n",
    "    # Crop and save individual leaves\n",
    "    cropped_paths = []\n",
    "    for i, contour in enumerate(valid_contours):\n",
    "        # Get bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Add padding around the bounding box\n",
    "        padding = 10\n",
    "        x_start = max(0, x - padding)\n",
    "        y_start = max(0, y - padding)\n",
    "        x_end = min(image.shape[1], x + w + padding)\n",
    "        y_end = min(image.shape[0], y + h + padding)\n",
    "        \n",
    "        # Crop the image (keeping original BGR format)\n",
    "        cropped = image[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Skip if cropped image is too small\n",
    "        if cropped.shape[0] < 20 or cropped.shape[1] < 20:\n",
    "            continue\n",
    "        \n",
    "        # Make the cropped image square\n",
    "        height, width, _ = cropped.shape\n",
    "        max_dim = max(height, width)\n",
    "        square_image = np.zeros((max_dim, max_dim, 3), dtype=np.uint8)  # Black background\n",
    "        y_offset = (max_dim - height) // 2\n",
    "        x_offset = (max_dim - width) // 2\n",
    "        square_image[y_offset:y_offset + height, x_offset:x_offset + width] = cropped\n",
    "        \n",
    "        # Resize to 224x224\n",
    "        resized_image = cv2.resize(square_image, (224, 224))\n",
    "        \n",
    "        # Save cropped image directly to output directory\n",
    "        filename = f\"{base_filename}_leaf_{i}.jpg\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, resized_image)  # Save in original BGR format\n",
    "        cropped_paths.append(output_path)\n",
    "    \n",
    "    return cropped_paths\n",
    "\n",
    "# Main function to process a folder of images\n",
    "def process_leaf_images(input_folder, output_folder):\n",
    "    # Load trained model\n",
    "    leaf_classifier = load_model('leaf_classifier_model.h5')\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each image in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "            \n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        # Create a copy for model input (needs RGB conversion for the model)\n",
    "        img_for_model = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # For model input, resize to model's expected size\n",
    "        img_size = (128, 128)  # Keep the model's expected input size\n",
    "        img_resized = cv2.resize(img_for_model, img_size)\n",
    "        img_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
    "        \n",
    "        # Classify as single leaf or bunch of leaves\n",
    "        bunch_prediction = leaf_classifier.predict(img_array)[0][0]\n",
    "        \n",
    "        if bunch_prediction < 0.5:  # Single leaf\n",
    "            # Make the image square first (using original BGR image)\n",
    "            height, width, _ = img.shape\n",
    "            max_dim = max(height, width)\n",
    "            square_image = np.zeros((max_dim, max_dim, 3), dtype=np.uint8)  # Black background\n",
    "            y_offset = (max_dim - height) // 2\n",
    "            x_offset = (max_dim - width) // 2\n",
    "            square_image[y_offset:y_offset + height, x_offset:x_offset + width] = img\n",
    "            \n",
    "            # Resize to 224x224\n",
    "            output_image = cv2.resize(square_image, (224, 224))\n",
    "            \n",
    "            # Save single leaf image directly to output folder\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            cv2.imwrite(output_path, output_image)  # Save in original BGR format\n",
    "        else:  # Bunch of leaves\n",
    "            # Crop individual leaves and save directly to output folder\n",
    "            crop_individual_leaves(image_path, output_folder, base_filename)\n",
    "    \n",
    "    print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing images...\")\n",
    "process_leaf_images('Classification/test', 'Classification/processed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epics_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
